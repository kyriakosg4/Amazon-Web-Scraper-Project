{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de25b4a0-dadc-47d6-8ba0-dc8e4cf90d34",
   "metadata": {},
   "source": [
    "# Web Scraping Amazon Product Details\n",
    "\n",
    "This project is designed to scrape product details from an Amazon product page, specifically the product title and price, and format this information for display. Additionally, the project sets up the foundation for sending an email notification if the product price drops.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b265e9-dd56-4cd2-8f0c-e43819ad21e5",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "\n",
    "Begin by importing the necessary libraries for web scraping and sending emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3829f4b-3d2e-4a37-a718-1146ed0a8d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import smtplib # for sending emails to yourself\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d8fc36-04c1-4bee-b2ba-65678706b15a",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "- we establish a connection to the Amazon product page using the `requests` library\n",
    "- We then use `BeautifulSoup` to parse the HTML content.\n",
    "- We extract the product title and price using the BeautifulSoup object\n",
    "- Finally, we print the product title and price in a formatted way\n",
    "- This will be the main part of our function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbfa6f8-627c-4888-85a6-1df48a2375f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Website \n",
    "\n",
    "url = 'https://www.amazon.com/Funny-Data-Systems-Business-Analyst/dp/B07FNW9FGJ/ref=sr_1_3?dchild=1&keywords=data%2Banalyst%2Btshirt&qid=1626655184&sr=8-3&customId=B0752XJYNL&th=1'\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "\n",
    "page = requests.get(url, headers = headers)\n",
    "\n",
    "soup1 = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "soup2 = BeautifulSoup(soup1.prettify(), 'html.parser')\n",
    "\n",
    "title = soup2.find(id = 'productTitle').get_text(strip = True)\n",
    "\n",
    "price = soup2.find(class_ = 'a-price-whole').get_text(strip=True)\n",
    "\n",
    "dollar_sign = soup2.find(class_ = 'a-price-symbol').get_text(strip=True)\n",
    "\n",
    "a_price = soup2.find(class_ = 'a-price-fraction').get_text(strip=True)  # strip=true, removes all the unecessary spaces \n",
    "\n",
    "\n",
    "print(title) \n",
    "formated_wind = (dollar_sign + price + a_price).center(45)  # moving the text on the right direction\n",
    "print(formated_wind)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb16f82-76bb-4b66-96ca-f5032e4c3d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "price = formated_wind.strip()[1:] # we want everything after the $\n",
    "title = title.strip()\n",
    "print(price)\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db83fb6-db22-4fc9-aa74-71348ab94d27",
   "metadata": {},
   "source": [
    "## Create the CSV file\n",
    "\n",
    "we create a CSV file to store the product details (title, price, and date) collected from the Amazon page. This CSV file will be used to log the data for future reference and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fbf054-6a2d-44ce-a0cb-1abb31d2df03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the csv file\n",
    "# run this once just for creating the csv file\n",
    "import csv\n",
    "\n",
    "# add one extra column for datetime\n",
    "import datetime\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "print(today)\n",
    "\n",
    "header = ['Title','Price','Date']\n",
    "data = [title,price,today]\n",
    "\n",
    "with open('AmazonWebScraperDataset.csv','w', newline = '', encoding = 'UTF8') as f: # name of file, write mode, no newline characters will be added\n",
    "                                                                                    # ex. \\n \n",
    "                                                                                    # write mode, it will overwrite the eixting file or if it doesnt exist\n",
    "                                                                                    # it will create a new one\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe1a9e1-b151-48ce-acb6-6b248bb2586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last step which to append every time a new row to our file\n",
    "\n",
    "with open('AmazonWebScraperDataset.csv','a+', newline = '', encoding = 'UTF8') as f:\n",
    "\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b970bd2-fbaf-4553-be4e-1f5459f3ed2b",
   "metadata": {},
   "source": [
    "## Importing Data with Pandas\n",
    "\n",
    "We use the Pandas library to import the data from the CSV file into a DataFrame and display its contents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a5bb8b-9732-4e24-8003-999b785273c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\User\\AmazonWebScraperDataset.csv\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac89527d-c401-4cd3-8304-7d50a75142eb",
   "metadata": {},
   "source": [
    "## Defining the `check_price` Function\n",
    "\n",
    "This function consolidates all the previous steps into a single process to check the product price, update the CSV file, and notify if the price falls below a specified threshold.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cf755c-b942-42ae-a8fd-3ab4df0794c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function so that we can be able to check the prize\n",
    "# combines all the previous steps\n",
    "\n",
    "def check_price():\n",
    "    url = 'https://www.amazon.com/Funny-Data-Systems-Business-Analyst/dp/B07FNW9FGJ/ref=sr_1_3?dchild=1&keywords=data%2Banalyst%2Btshirt&qid=1626655184&sr=8-3&customId=B0752XJYNL&th=1'\n",
    "\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "\n",
    "    page = requests.get(url, headers = headers)\n",
    "\n",
    "    soup1 = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    soup2 = BeautifulSoup(soup1.prettify(), 'html.parser')\n",
    "\n",
    "    title = soup2.find(id = 'productTitle').get_text()\n",
    "\n",
    "    price = soup2.find(class_ = 'a-price-whole').get_text(strip=True)\n",
    "\n",
    "    dollar_sign = soup2.find(class_ = 'a-price-symbol').get_text(strip=True)\n",
    "\n",
    "    a_price = soup2.find(class_ = 'a-price-fraction').get_text(strip=True)  # strip=true, removes all the unecessary spaces \n",
    "\n",
    "    price = formated_wind.strip()[1:] # its taking everything after the $\n",
    "    title = title.strip()\n",
    "\n",
    "    import datetime\n",
    "\n",
    "    today = datetime.date.today()\n",
    "\n",
    "    import csv\n",
    "\n",
    "    header = ['Title','Price','Date']\n",
    "    data = [title,price,today]\n",
    "\n",
    "    with open('AmazonWebScraperDataset.csv','a+', newline = '', encoding = 'UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data)\n",
    "\n",
    "    # we set a price which the program will let us be notified when it falls under this value\n",
    "    if (price < 14):\n",
    "        send_mail()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01dfc7f-39a1-430d-bb60-e7a976c6c037",
   "metadata": {},
   "source": [
    "## Setting Up the Program Execution Timer\n",
    "\n",
    "We implement a timer to repeatedly execute the `check_price()` function at regular intervals. This allows the program to continuously monitor the product price and take action if the price falls below the specified threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ecdc7-fa39-4d06-a342-c4a7bc4f94ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set program execution timer \n",
    "while(True):\n",
    "    check_price()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b27965-a194-47f4-946c-22c0b78ca397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\User\\AmazonWebScraperDataset.csv\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db3e830-3c07-4929-a6ac-744232484779",
   "metadata": {},
   "source": [
    "## Sending Email Notifications\n",
    "\n",
    "In this section, we define the `send_mail()` function to send an email notification when the product price falls below a specified threshold. This feature can be used to alert you to take action, such as purchasing the product. For that reason we use `smtplib` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4489df2d-aaed-4e6d-b47f-43a6aae4ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If uou want to try sending yourself an email (just for fun) when a price hits below a certain level you can try it\n",
    "# out with this script\n",
    "\n",
    "def send_mail():\n",
    "    server = smtplib.SMTP_SSL('smtp.gmail.com',465) # SMTP connection to Gmail's SMTP server using SSL encryption on port 465\n",
    "    server.ehlo() # identifies the client to the SMTP server\n",
    "    #server.starttls()\n",
    "    #server.ehlo()\n",
    "    server.login('kyris1---@gmail.com','xxxxxxxxxxxxxx')\n",
    "    \n",
    "    subject = \"The Shirt you want is below $15! Now is your chance to buy!\"\n",
    "    body = \"Kyriakos, This is the moment we have been waiting for. Now is your chance to pick up the shirt of your dreams. Don't mess it up! Link here: https://www.amazon.com/Funny-Data-Systems-Business-Analyst/dp/B07FNW9FGJ/ref=sr_1_3?dchild=1&keywords=data+analyst+tshirt&qid=1626655184&sr=8-3\"\n",
    "   \n",
    "    msg = f\"Subject: {subject}\\n\\n{body}\"  # f'' it allows us to embed expressions s inside string literals, using curly braces {}\n",
    "    \n",
    "    server.sendmail(\n",
    "        'kyris---@gmail.com', # sender \n",
    "        'kyris---@gmail.com', # recipient\n",
    "        msg\n",
    "     \n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
